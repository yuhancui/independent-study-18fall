{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
    "\n",
    "In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](svm_s.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)# display all the columns\n",
    "raw_data = pd.read_csv('a_20s_1600_Het_h_0.4MAF_0.2_r_50_EDM-2_01.txt', sep = \"\\t\")# read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N0</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>N15</th>\n",
       "      <th>M0P0</th>\n",
       "      <th>M1P0</th>\n",
       "      <th>M2P0</th>\n",
       "      <th>M3P0</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N0  N1  N2  N3  N4  N5  N6  N7  N8  N9  N10  N11  N12  N13  N14  N15  M0P0  \\\n",
       "0   0   0   1   1   0   0   2   0   0   2    2    0    0    1    2    0     1   \n",
       "1   0   2   1   1   0   1   0   0   0   1    1    0    0    2    1    0     1   \n",
       "2   0   0   0   0   0   1   0   0   0   1    0    0    0    1    1    0     1   \n",
       "3   0   2   0   1   0   0   0   0   0   1    1    0    0    2    0    0     1   \n",
       "4   0   0   1   1   0   0   1   1   0   0    0    0    0    1    1    1     1   \n",
       "\n",
       "   M1P0  M2P0  M3P0  Class  \n",
       "0     1     1     1      1  \n",
       "1     1     1     1      1  \n",
       "2     1     0     1      1  \n",
       "3     1     1     1      1  \n",
       "4     1     1     0      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1600\n",
      "Number of columns: 21\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of rows: \" + str(raw_data.shape[0])) # row count\n",
    "print (\"Number of columns: \" + str(raw_data.shape[1])) # column count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N0</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>N15</th>\n",
       "      <th>M0P0</th>\n",
       "      <th>M1P0</th>\n",
       "      <th>M2P0</th>\n",
       "      <th>M3P0</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.719375</td>\n",
       "      <td>0.379375</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.488125</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.354375</td>\n",
       "      <td>1.007500</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.080625</td>\n",
       "      <td>0.258750</td>\n",
       "      <td>0.83875</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.403750</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.53000</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.516250</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.275583</td>\n",
       "      <td>0.675211</td>\n",
       "      <td>0.560710</td>\n",
       "      <td>0.691202</td>\n",
       "      <td>0.264173</td>\n",
       "      <td>0.703671</td>\n",
       "      <td>0.611427</td>\n",
       "      <td>0.668455</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.715202</td>\n",
       "      <td>0.630495</td>\n",
       "      <td>0.285790</td>\n",
       "      <td>0.477693</td>\n",
       "      <td>0.71191</td>\n",
       "      <td>0.687601</td>\n",
       "      <td>0.569815</td>\n",
       "      <td>0.579275</td>\n",
       "      <td>0.60152</td>\n",
       "      <td>0.581902</td>\n",
       "      <td>0.572224</td>\n",
       "      <td>0.500156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                N0           N1           N2           N3           N4  \\\n",
       "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "mean      0.081250     0.719375     0.379375     0.806250     0.072500   \n",
       "std       0.275583     0.675211     0.560710     0.691202     0.264173   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "max       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
       "\n",
       "                N5           N6           N7           N8           N9  \\\n",
       "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "mean      0.837500     0.488125     0.653125     0.354375     1.007500   \n",
       "std       0.703671     0.611427     0.668455     0.541042     0.715202   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     2.000000   \n",
       "max       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
       "\n",
       "               N10          N11          N12         N13          N14  \\\n",
       "count  1600.000000  1600.000000  1600.000000  1600.00000  1600.000000   \n",
       "mean      0.515000     0.080625     0.258750     0.83875     0.900000   \n",
       "std       0.630495     0.285790     0.477693     0.71191     0.687601   \n",
       "min       0.000000     0.000000     0.000000     0.00000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.00000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.00000     1.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.00000     1.000000   \n",
       "max       2.000000     2.000000     2.000000     2.00000     2.000000   \n",
       "\n",
       "               N15         M0P0        M1P0         M2P0         M3P0  \\\n",
       "count  1600.000000  1600.000000  1600.00000  1600.000000  1600.000000   \n",
       "mean      0.403750     0.530000     0.53000     0.518750     0.516250   \n",
       "std       0.569815     0.579275     0.60152     0.581902     0.572224   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.00000     1.000000     1.000000   \n",
       "max       2.000000     2.000000     2.00000     2.000000     2.000000   \n",
       "\n",
       "             Class  \n",
       "count  1600.000000  \n",
       "mean      0.500000  \n",
       "std       0.500156  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.500000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe() # descriptive statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().values.any() # check missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.distplot(raw_data['Class'],kde=False) # The outcome is labeled as 'class'\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112be4390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use heat map to visualize correlation between each column\n",
    "corr = raw_data[['N0','N1','N2','N3','N4','N5','N6','N7','N8','N9','N10','N11','N12','N13','N14','N15','M0P0','M1P0','M2P0','M3P0','Class']].corr()\n",
    "sb.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From heat map, we noticed that N0P0, M1P0, M2P0 and M3P0 are correlated with 'Class'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N0</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>N15</th>\n",
       "      <th>M0P0</th>\n",
       "      <th>M1P0</th>\n",
       "      <th>M2P0</th>\n",
       "      <th>M3P0</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028505</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.017031</td>\n",
       "      <td>-0.012241</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.016489</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>-0.027643</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>-0.009907</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1</th>\n",
       "      <td>0.028505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.045569</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>-0.009164</td>\n",
       "      <td>0.044185</td>\n",
       "      <td>-0.043989</td>\n",
       "      <td>-0.022059</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>-0.022036</td>\n",
       "      <td>-0.026798</td>\n",
       "      <td>-0.042155</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>-0.032048</td>\n",
       "      <td>-0.014438</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>-0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N2</th>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023226</td>\n",
       "      <td>0.046411</td>\n",
       "      <td>0.039052</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>-0.019100</td>\n",
       "      <td>0.051320</td>\n",
       "      <td>-0.035171</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>-0.007569</td>\n",
       "      <td>-0.014152</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>-0.026440</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>-0.014845</td>\n",
       "      <td>-0.014296</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.041641</td>\n",
       "      <td>-0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N3</th>\n",
       "      <td>0.017031</td>\n",
       "      <td>0.045569</td>\n",
       "      <td>-0.023226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022348</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>-0.005448</td>\n",
       "      <td>0.042595</td>\n",
       "      <td>0.024844</td>\n",
       "      <td>-0.062843</td>\n",
       "      <td>0.025329</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>-0.028009</td>\n",
       "      <td>0.047040</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>-0.012027</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.018090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N4</th>\n",
       "      <td>-0.012241</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>0.046411</td>\n",
       "      <td>-0.022348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017326</td>\n",
       "      <td>-0.014026</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>-0.040326</td>\n",
       "      <td>-0.019487</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>-0.010957</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>0.038077</td>\n",
       "      <td>-0.034656</td>\n",
       "      <td>-0.033374</td>\n",
       "      <td>-0.033258</td>\n",
       "      <td>-0.061581</td>\n",
       "      <td>-0.056799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N5</th>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.009164</td>\n",
       "      <td>0.039052</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>-0.017326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.070218</td>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.030982</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>-0.016136</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>-0.010957</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>0.030356</td>\n",
       "      <td>0.039178</td>\n",
       "      <td>0.031985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N6</th>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.044185</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>-0.005448</td>\n",
       "      <td>-0.014026</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>-0.020355</td>\n",
       "      <td>-0.024109</td>\n",
       "      <td>-0.006838</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.031939</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.005975</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.004982</td>\n",
       "      <td>-0.012557</td>\n",
       "      <td>-0.028942</td>\n",
       "      <td>-0.015338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N7</th>\n",
       "      <td>0.010503</td>\n",
       "      <td>-0.043989</td>\n",
       "      <td>-0.019100</td>\n",
       "      <td>0.042595</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.070218</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012661</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>-0.004711</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>-0.040074</td>\n",
       "      <td>-0.007484</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.033914</td>\n",
       "      <td>-0.031852</td>\n",
       "      <td>-0.010288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N8</th>\n",
       "      <td>0.016489</td>\n",
       "      <td>-0.022059</td>\n",
       "      <td>0.051320</td>\n",
       "      <td>0.024844</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.019938</td>\n",
       "      <td>-0.020355</td>\n",
       "      <td>-0.012661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006873</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.011400</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>-0.039169</td>\n",
       "      <td>-0.009993</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N9</th>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>-0.035171</td>\n",
       "      <td>-0.062843</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>-0.024109</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>-0.006873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>-0.018259</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>-0.030787</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>-0.018658</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.049251</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.033218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N10</th>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.025329</td>\n",
       "      <td>-0.040326</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>-0.006838</td>\n",
       "      <td>-0.004711</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015393</td>\n",
       "      <td>-0.017048</td>\n",
       "      <td>-0.014114</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>-0.056905</td>\n",
       "      <td>-0.008082</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.019744</td>\n",
       "      <td>-0.019832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N11</th>\n",
       "      <td>-0.027643</td>\n",
       "      <td>-0.022036</td>\n",
       "      <td>-0.007569</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>-0.019487</td>\n",
       "      <td>0.030982</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.018259</td>\n",
       "      <td>-0.015393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010897</td>\n",
       "      <td>-0.074383</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>-0.050507</td>\n",
       "      <td>-0.008622</td>\n",
       "      <td>-0.048582</td>\n",
       "      <td>-0.009929</td>\n",
       "      <td>-0.037189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N12</th>\n",
       "      <td>0.020725</td>\n",
       "      <td>-0.026798</td>\n",
       "      <td>-0.014152</td>\n",
       "      <td>-0.028009</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>0.031939</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>-0.011400</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>-0.017048</td>\n",
       "      <td>-0.010897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020675</td>\n",
       "      <td>-0.052550</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>-0.043890</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N13</th>\n",
       "      <td>0.006256</td>\n",
       "      <td>-0.042155</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>0.047040</td>\n",
       "      <td>-0.010957</td>\n",
       "      <td>-0.016136</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>-0.040074</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>-0.030787</td>\n",
       "      <td>-0.014114</td>\n",
       "      <td>-0.074383</td>\n",
       "      <td>-0.020675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018908</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.022353</td>\n",
       "      <td>-0.012063</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>-0.011986</td>\n",
       "      <td>0.008782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N14</th>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>-0.026440</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.007484</td>\n",
       "      <td>-0.039169</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>-0.052550</td>\n",
       "      <td>-0.018908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>-0.014445</td>\n",
       "      <td>0.051107</td>\n",
       "      <td>-0.012504</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>-0.010911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N15</th>\n",
       "      <td>-0.009907</td>\n",
       "      <td>-0.032048</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.038077</td>\n",
       "      <td>-0.010957</td>\n",
       "      <td>-0.005975</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>-0.009993</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>-0.056905</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019667</td>\n",
       "      <td>-0.004343</td>\n",
       "      <td>-0.019073</td>\n",
       "      <td>-0.014380</td>\n",
       "      <td>-0.030721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M0P0</th>\n",
       "      <td>0.008227</td>\n",
       "      <td>-0.014438</td>\n",
       "      <td>-0.014845</td>\n",
       "      <td>-0.012027</td>\n",
       "      <td>-0.034656</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>-0.018658</td>\n",
       "      <td>-0.008082</td>\n",
       "      <td>-0.050507</td>\n",
       "      <td>-0.043890</td>\n",
       "      <td>0.022353</td>\n",
       "      <td>-0.014445</td>\n",
       "      <td>-0.019667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334838</td>\n",
       "      <td>0.378669</td>\n",
       "      <td>0.334359</td>\n",
       "      <td>0.595758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1P0</th>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>-0.014296</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>-0.033374</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>-0.004982</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>-0.008622</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>-0.012063</td>\n",
       "      <td>0.051107</td>\n",
       "      <td>-0.004343</td>\n",
       "      <td>0.334838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377172</td>\n",
       "      <td>0.349248</td>\n",
       "      <td>0.594514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M2P0</th>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.033258</td>\n",
       "      <td>0.030356</td>\n",
       "      <td>-0.012557</td>\n",
       "      <td>-0.033914</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.049251</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.048582</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>-0.012504</td>\n",
       "      <td>-0.019073</td>\n",
       "      <td>0.378669</td>\n",
       "      <td>0.377172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340912</td>\n",
       "      <td>0.599515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M3P0</th>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>-0.041641</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>-0.061581</td>\n",
       "      <td>0.039178</td>\n",
       "      <td>-0.028942</td>\n",
       "      <td>-0.031852</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>-0.019744</td>\n",
       "      <td>-0.009929</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>-0.011986</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>-0.014380</td>\n",
       "      <td>0.334359</td>\n",
       "      <td>0.349248</td>\n",
       "      <td>0.340912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0.004537</td>\n",
       "      <td>-0.004630</td>\n",
       "      <td>-0.005575</td>\n",
       "      <td>0.018090</td>\n",
       "      <td>-0.056799</td>\n",
       "      <td>0.031985</td>\n",
       "      <td>-0.015338</td>\n",
       "      <td>-0.010288</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.033218</td>\n",
       "      <td>-0.019832</td>\n",
       "      <td>-0.037189</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.030721</td>\n",
       "      <td>0.595758</td>\n",
       "      <td>0.594514</td>\n",
       "      <td>0.599515</td>\n",
       "      <td>0.572507</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             N0        N1        N2        N3        N4        N5        N6  \\\n",
       "N0     1.000000  0.028505  0.027041  0.017031 -0.012241  0.000403  0.002018   \n",
       "N1     0.028505  1.000000  0.010472  0.045569  0.008949 -0.009164  0.044185   \n",
       "N2     0.027041  0.010472  1.000000 -0.023226  0.046411  0.039052  0.014061   \n",
       "N3     0.017031  0.045569 -0.023226  1.000000 -0.022348  0.005947 -0.005448   \n",
       "N4    -0.012241  0.008949  0.046411 -0.022348  1.000000 -0.017326 -0.014026   \n",
       "N5     0.000403 -0.009164  0.039052  0.005947 -0.017326  1.000000  0.011501   \n",
       "N6     0.002018  0.044185  0.014061 -0.005448 -0.014026  0.011501  1.000000   \n",
       "N7     0.010503 -0.043989 -0.019100  0.042595  0.000841  0.070218  0.009042   \n",
       "N8     0.016489 -0.022059  0.051320  0.024844  0.008281  0.019938 -0.020355   \n",
       "N9     0.009598  0.017311 -0.035171 -0.062843  0.030221  0.022306 -0.024109   \n",
       "N10    0.054169  0.010628  0.036079  0.025329 -0.040326  0.023822 -0.006838   \n",
       "N11   -0.027643 -0.022036 -0.007569  0.009478 -0.019487  0.030982  0.000114   \n",
       "N12    0.020725 -0.026798 -0.014152 -0.028009  0.014793 -0.008791  0.031939   \n",
       "N13    0.006256 -0.042155  0.020177  0.047040 -0.010957 -0.016136  0.014276   \n",
       "N14    0.036304  0.009564 -0.026440 -0.010527  0.029609  0.014218 -0.062328   \n",
       "N15   -0.009907 -0.032048  0.017467  0.003434  0.038077 -0.010957 -0.005975   \n",
       "M0P0   0.008227 -0.014438 -0.014845 -0.012027 -0.034656  0.005830 -0.005174   \n",
       "M1P0   0.019241  0.007653 -0.014296  0.009476 -0.033374  0.032210 -0.004982   \n",
       "M2P0   0.006094  0.007829 -0.007439 -0.004956 -0.033258  0.030356 -0.012557   \n",
       "M3P0   0.015417  0.004526 -0.041641  0.007965 -0.061581  0.039178 -0.028942   \n",
       "Class  0.004537 -0.004630 -0.005575  0.018090 -0.056799  0.031985 -0.015338   \n",
       "\n",
       "             N7        N8        N9       N10       N11       N12       N13  \\\n",
       "N0     0.010503  0.016489  0.009598  0.054169 -0.027643  0.020725  0.006256   \n",
       "N1    -0.043989 -0.022059  0.017311  0.010628 -0.022036 -0.026798 -0.042155   \n",
       "N2    -0.019100  0.051320 -0.035171  0.036079 -0.007569 -0.014152  0.020177   \n",
       "N3     0.042595  0.024844 -0.062843  0.025329  0.009478 -0.028009  0.047040   \n",
       "N4     0.000841  0.008281  0.030221 -0.040326 -0.019487  0.014793 -0.010957   \n",
       "N5     0.070218  0.019938  0.022306  0.023822  0.030982 -0.008791 -0.016136   \n",
       "N6     0.009042 -0.020355 -0.024109 -0.006838  0.000114  0.031939  0.014276   \n",
       "N7     1.000000 -0.012661  0.005445 -0.004711  0.012266  0.012939 -0.040074   \n",
       "N8    -0.012661  1.000000 -0.006873  0.003657  0.009244 -0.011400  0.007191   \n",
       "N9     0.005445 -0.006873  1.000000  0.024714 -0.018259 -0.014836 -0.030787   \n",
       "N10   -0.004711  0.003657  0.024714  1.000000 -0.015393 -0.017048 -0.014114   \n",
       "N11    0.012266  0.009244 -0.018259 -0.015393  1.000000 -0.010897 -0.074383   \n",
       "N12    0.012939 -0.011400 -0.014836 -0.017048 -0.010897  1.000000 -0.020675   \n",
       "N13   -0.040074  0.007191 -0.030787 -0.014114 -0.074383 -0.020675  1.000000   \n",
       "N14   -0.007484 -0.039169 -0.002289  0.013560  0.047419 -0.052550 -0.018908   \n",
       "N15    0.037897 -0.009993  0.006376 -0.056905  0.030401  0.011137  0.003342   \n",
       "M0P0   0.000242 -0.007004 -0.018658 -0.008082 -0.050507 -0.043890  0.022353   \n",
       "M1P0   0.000233 -0.016353  0.032912  0.008707 -0.008622 -0.000914 -0.012063   \n",
       "M2P0  -0.033914  0.025563  0.049251 -0.017813 -0.048582  0.007284 -0.007794   \n",
       "M3P0  -0.031852  0.000578  0.022624 -0.019744 -0.009929  0.007487 -0.011986   \n",
       "Class -0.010288  0.001156  0.033218 -0.019832 -0.037189  0.002618  0.008782   \n",
       "\n",
       "            N14       N15      M0P0      M1P0      M2P0      M3P0     Class  \n",
       "N0     0.036304 -0.009907  0.008227  0.019241  0.006094  0.015417  0.004537  \n",
       "N1     0.009564 -0.032048 -0.014438  0.007653  0.007829  0.004526 -0.004630  \n",
       "N2    -0.026440  0.017467 -0.014845 -0.014296 -0.007439 -0.041641 -0.005575  \n",
       "N3    -0.010527  0.003434 -0.012027  0.009476 -0.004956  0.007965  0.018090  \n",
       "N4     0.029609  0.038077 -0.034656 -0.033374 -0.033258 -0.061581 -0.056799  \n",
       "N5     0.014218 -0.010957  0.005830  0.032210  0.030356  0.039178  0.031985  \n",
       "N6    -0.062328 -0.005975 -0.005174 -0.004982 -0.012557 -0.028942 -0.015338  \n",
       "N7    -0.007484  0.037897  0.000242  0.000233 -0.033914 -0.031852 -0.010288  \n",
       "N8    -0.039169 -0.009993 -0.007004 -0.016353  0.025563  0.000578  0.001156  \n",
       "N9    -0.002289  0.006376 -0.018658  0.032912  0.049251  0.022624  0.033218  \n",
       "N10    0.013560 -0.056905 -0.008082  0.008707 -0.017813 -0.019744 -0.019832  \n",
       "N11    0.047419  0.030401 -0.050507 -0.008622 -0.048582 -0.009929 -0.037189  \n",
       "N12   -0.052550  0.011137 -0.043890 -0.000914  0.007284  0.007487  0.002618  \n",
       "N13   -0.018908  0.003342  0.022353 -0.012063 -0.007794 -0.011986  0.008782  \n",
       "N14    1.000000  0.015323 -0.014445  0.051107 -0.012504  0.010490 -0.010911  \n",
       "N15    0.015323  1.000000 -0.019667 -0.004343 -0.019073 -0.014380 -0.030721  \n",
       "M0P0  -0.014445 -0.019667  1.000000  0.334838  0.378669  0.334359  0.595758  \n",
       "M1P0   0.051107 -0.004343  0.334838  1.000000  0.377172  0.349248  0.594514  \n",
       "M2P0  -0.012504 -0.019073  0.378669  0.377172  1.000000  0.340912  0.599515  \n",
       "M3P0   0.010490 -0.014380  0.334359  0.349248  0.340912  1.000000  0.572507  \n",
       "Class -0.010911 -0.030721  0.595758  0.594514  0.599515  0.572507  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only keep features:N0P0, M1P0, M2P0 and M3P0\n",
    "data_clean = raw_data.iloc[:, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data_clean.iloc[:, -1].values \n",
    "X = data_clean.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the data \n",
    "# All algorithms that are distance based require scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After feature selection, feature space holds 1600 observations and 4 features\n",
      "Unique target labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print (\"After feature selection, feature space holds %d observations and %d features\" % X.shape)\n",
    "print (\"Unique target labels:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model Training and Result Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function does 10-fold. It saves the result at each time as different parts of y_pred. \n",
    "# In the end, it returns the y_pred as the result of all the 10-fold.\n",
    "def run_cv(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=10,shuffle=True) # Total number of elementsNumber of folds default=3Whether to shuffle the data before splitting into batches\n",
    "    y_pred = y.copy()\n",
    "    clf = clf_class(**kwargs)\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM Model and Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    return np.mean(y_true == y_pred) # NumPy interpretes True and False as 1. and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify Using a RBF(Radial Basis Function) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 10-fold cross validation accuracy: 0.93875\n"
     ]
    }
   ],
   "source": [
    "# In sklearn.svm, default kernal is rbf. Resultes in flexible non-linear decision boundaries\n",
    "SVM_CV_result_rbf = run_cv(X, y, SVC)\n",
    "print (\"SVM 10-fold cross validation accuracy: \" + str(accuracy(y, SVM_CV_result_rbf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify Using a Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 10-fold cross validation accuracy: 0.9075\n"
     ]
    }
   ],
   "source": [
    "# Results in linear decision boundaries\n",
    "SVM_CV_result_linear = run_cv(X, y, SVC, kernel = 'linear')\n",
    "print (\"SVM 10-fold cross validation accuracy: \" + str(accuracy(y, SVM_CV_result_linear)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify Using a Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 10-fold cross validation accuracy: 0.935\n"
     ]
    }
   ],
   "source": [
    "# Results in flexible non-linear decision boundaries\n",
    "SVM_CV_result_poly = run_cv(X, y, SVC, kernel = 'poly')\n",
    "print (\"SVM 10-fold cross validation accuracy: \" + str(accuracy(y, SVM_CV_result_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with RBF Kernel  had the best performance. Thus, I will continue with RBF Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Optimal Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that an SVC classifier using an RBF kernel has two parameters: gamma and C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma<br>\n",
    "Gamma is a parameter of the RBF kernel and can be thought of as the spread of the kernel and therefore the decision region. When gamma is low, the curve of the decision boundary is very low and thus the decision region is very broad. When gamma is high, the curve of the decision boundary is high, which creates islands of decision-boundaries around data points.\n",
    "\n",
    "C<br>\n",
    "C is a parameter of the SVC learner and is the penalty for misclassifying a data point. When C is small, the classifier is okay with misclassified data points (high bias, low variance). When C is large, the classifier is heavily penalized for misclassified data and therefore bends over backwards avoid any misclassified data points (low bias, high variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bias-variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](biasvariance.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_grid_search_metrics(grid_search):\n",
    "    print (\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_params_\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {\n",
    "    'C':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'gamma':[0.001, 0.01, 0.1, 1, 10]    \n",
    "}\n",
    "Grid_SVM = GridSearchCV(SVC(),parameters)\n",
    "Grid_SVM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.941\n",
      "Best parameters set:\n",
      "\tC: 0.1\n",
      "\tgamma: 1\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_metrics(Grid_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 10-fold cross validation accuracy: 0.940625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "score = cross_val_score(SVC(C = 0.1, gamma = 1), X, y, cv=10)\n",
    "print (\"SVM 10-fold cross validation accuracy: \" + str(np.mean(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_CV_result = run_cv(X, y, SVC,C = 0.1, gamma = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(y, SVM_CV_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM model after parameter optimization:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.90      0.94       800\n",
      "          1       0.91      0.98      0.94       800\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Classification Report for SVM model after parameter optimization:\\n\")\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:<br>\n",
    "https://en.wikipedia.org/wiki/Support_vector_machine<br>\n",
    "https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html<br>\n",
    "http://scikit-learn.org/stable/modules/svm.html#svm-kernels<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
